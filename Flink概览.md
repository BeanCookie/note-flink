# 什么是Flink
Apache Flink是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态的计算，能够部署在各种集群环境，可以在内存中对各种规模大小的数据进行快速计算。
# 统一处理批数据与流数据
传统的处理大批数据的方式，都是先将数据存储到分布式文件系统或者分布式数据库中，然后在定时处理这些数据这种情况下数据延迟通常为天或者小时为单位。随着对数据实时性的要求越来越高，高延迟的的批处理无法满足业务需求。

为了解决这些难题Apache Storm这类流数据处理引擎孕育而生，Storm将数据流抽象成Strem，这是一种无界的、以分布式方式并行创建和处理的Tuple序列，所有对Stream的操作都在Bolt进行。与批处理任务不同Apache Storm任务开始之后就会一直运行，并将输入数据的延迟降低到以事件为单位。

随着批处理与流处理技术的不断发展，逐渐演化出将两者有效结合的Lambda架构。这是就会产生另一个问题相同的业务往往需要维护批处理和流处理两套代码。为了解决这一问题Google提出了Dataflow模型，提供统一编程接口开发批处理与流处理这两种任务，并保证它们的底层执行逻辑是一致的。对用户来说流批一体很大程度上减少了开发维护的成本。作为Dataflow模型的最早实践者之一，Apache Flink在流批一体特性的完成度上在开源项目中具有十分领先的地位。

# 流处理中的时间与窗口
## 处理时间与事件时间
在不同的应用场景中时间语义是各不相同的，Flink作为一个先进的分布式流处理引擎，支持处理时间和事件时间两种时间语义。
处理时间（ Processing Time）是来模拟我们真实世界的时间，可以通过直接去调用本地机器的时间获取处理时间。事件时间（Event Time）是数据世界的时间，就是我们要处理的数据流世界里面的时间，可以根据每一条处理记录所携带的时间戳来判定获取事件时间。
## 窗口
Flink是一个天然支持无限流数据处理的分布式计算框架，在Flink中Window可以将无限流切分成有限流，是处理有限流的核心组件。现在Flink中Window 可以是时间驱动的（Time Window），也可以是数据驱动的（Count Window）。

# 流处理中的状态
尽管数据流中的许多操作一次仅处理一个事件。但某些操作会记录多个事件的信息，这些操作称为有状态。
使用状态的场景：
1. 去重：比如上游的系统数据可能会有重复，落到下游系统时希望把重复的数据都去掉。去重需要先了解哪些数据来过，哪些数据还没有来，也就是把所有的主键都记录下来，当一条数据到来后，能够看到在主键当中是否存在。
2. 窗口计算：比如统计每分钟Nginx日志API被访问了多少次。窗口是一分钟计算一次，在窗口触发前，如 08:00 ~ 08:01 这个窗口，前59秒的数据来了需要先放入内存，即需要把这个窗口之内的数据先保留下来，等到 8:01 时一分钟后，再将整个窗口内触发的数据输出。未触发的窗口数据也是一种状态。
3. 访问历史数据：比如与昨天的数据进行对比，需要访问一些历史数据。如果每次从外部去读，对资源的消耗可能比较大，所以也希望把这些历史数据也放入状态中做对比。
4. 机器学习/深度学习：如训练的模型以及当前模型的参数也是一种状态，机器学习可能每次都用有一个数据集，需要在数据集上进行学习，对模型进行一个反馈。

# 状态如何保存及恢复
## Checkpoint
Flink状态保存主要依靠Checkpoint机制，Checkpoint会定时制作分布式快照，对程序中的状态进行备份。如果要从Checkpoint恢复，必要条件是数据源需要支持数据重新发送。
## Savepoint
Savepoint与Checkpoint 类似，同样是把状态存储到外部介质。当作业失败时可以从外部恢复。Savepoint与Checkpoint的主要区别如下：
1. 从触发管理方式来讲，Checkpoint由Flink自动触发并管理，而Savepoint由用户手动触发并人肉管理
2. 从用途来讲，Checkpoint在Task发生异常时快速恢复，例如网络抖动或超时异常，而Savepoint有计划地进行备份，使作业能停止后再恢复，例如修改代码、调整并发
3. 最后从特点来讲，Checkpoint比较轻量级，作业出现问题会自动从故障中恢复，在作业停止后默认清除；而Savepoint比较持久，以标准格式存储，允许代码或配置发生改变，恢复需要启动作业手动指定一个路径恢复